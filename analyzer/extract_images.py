"""
ç ”æŠ¥åˆ†æç³»ç»Ÿ - PDFå›¾ç‰‡æå–å·¥å…·

ä»ç ”æŠ¥PDFä¸­æå–æ‰€æœ‰æœ‰æ„ä¹‰çš„å›¾è¡¨å’Œå›¾ç‰‡ï¼Œ
ä¿å­˜åˆ° reports/{TICKER}/analysis/images/ ç›®å½•ä¸‹ã€‚

ç”¨æ³•: uv run python extract_images.py GOOGL
      uv run python extract_images.py GOOGL --min-size 200
"""

import sys
import os
import argparse
from pathlib import Path

# Windowsç¯å¢ƒä¸‹å¼ºåˆ¶ä½¿ç”¨UTF-8ç¼–ç è¾“å‡º
if sys.platform == "win32":
    os.environ["PYTHONIOENCODING"] = "utf-8"
    sys.stdout.reconfigure(encoding="utf-8")
    sys.stderr.reconfigure(encoding="utf-8")

try:
    import fitz  # PyMuPDF
except ImportError:
    print("âŒ è¯·å…ˆå®‰è£… pymupdf: uv add pymupdf")
    sys.exit(1)

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent
REPORTS_DIR = PROJECT_ROOT / "reports"


def extract_images(ticker: str, min_size: int = 100) -> dict:
    """
    ä»æŒ‡å®šæ ‡çš„çš„æ‰€æœ‰PDFç ”æŠ¥ä¸­æå–å›¾ç‰‡

    å‚æ•°:
        ticker: æ ‡çš„ä»£ç 
        min_size: æœ€å°å›¾ç‰‡å°ºå¯¸ï¼ˆå®½å’Œé«˜éƒ½å¿…é¡» >= æ­¤å€¼ï¼‰ï¼Œè¿‡æ»¤å°å›¾æ ‡

    è¿”å›:
        æå–ç»“æœå­—å…¸ {pdf_filename: [image_info, ...]}
    """
    originals_dir = REPORTS_DIR / ticker / "originals"
    output_dir = REPORTS_DIR / ticker / "analysis" / "images"
    output_dir.mkdir(parents=True, exist_ok=True)

    if not originals_dir.exists():
        print(f"âŒ ç ”æŠ¥ç›®å½•ä¸å­˜åœ¨: {originals_dir}")
        return {}

    pdf_files = list(originals_dir.glob("*.pdf"))
    if not pdf_files:
        print(f"âŒ æœªæ‰¾åˆ°PDFæ–‡ä»¶: {originals_dir}")
        return {}

    print(f"\n{'='*60}")
    print(f"  ğŸ–¼ï¸  æå– {ticker} ç ”æŠ¥å›¾è¡¨")
    print(f"{'='*60}\n")
    print(f"  ğŸ“ æ¥æº: {originals_dir}")
    print(f"  ğŸ“ è¾“å‡º: {output_dir}")
    print(f"  ğŸ“ æœ€å°å°ºå¯¸: {min_size}x{min_size}")
    print()

    results = {}

    for pdf_path in sorted(pdf_files):
        pdf_name = pdf_path.name
        # æˆªæ–­æ–‡ä»¶åå‰ç¼€ï¼ˆæœ€å¤š30å­—ç¬¦ï¼‰ç”¨äºå›¾ç‰‡å‘½å
        prefix = pdf_name.replace(".pdf", "")[:30]

        doc = fitz.open(str(pdf_path))
        total_pages = len(doc)
        extracted = []

        for page_num in range(total_pages):
            page = doc[page_num]
            images = page.get_images(full=True)

            for img_idx, img_info in enumerate(images):
                xref = img_info[0]
                try:
                    base_image = doc.extract_image(xref)
                except Exception:
                    continue

                if not base_image:
                    continue

                w = base_image["width"]
                h = base_image["height"]

                # è¿‡æ»¤å°å›¾æ ‡
                if w < min_size or h < min_size:
                    continue

                ext = base_image["ext"]
                img_data = base_image["image"]
                img_filename = f"{prefix}_p{page_num + 1}_img{img_idx + 1}.{ext}"
                img_path = output_dir / img_filename

                with open(img_path, "wb") as f:
                    f.write(img_data)

                img_info_dict = {
                    "filename": img_filename,
                    "page": page_num + 1,
                    "width": w,
                    "height": h,
                    "size_bytes": len(img_data),
                    "format": ext,
                }
                extracted.append(img_info_dict)
                print(f"  ğŸ“¸ {img_filename} ({w}x{h})")

        doc.close()
        results[pdf_name] = extracted

        # ç»Ÿè®¡æœ‰æ•ˆå›¾è¡¨ï¼ˆæ’é™¤çº¯é»‘/çº¯æ·±è‰²èƒŒæ™¯å›¾ï¼‰
        meaningful = [img for img in extracted if img["width"] >= 400 and img["height"] >= 300]
        print(f"  ğŸ“„ {pdf_name}: {len(extracted)} å¼ å›¾ç‰‡æå–, {len(meaningful)} å¼ æœ‰æ•ˆå›¾è¡¨")
        print()

    # æ±‡æ€»
    total_images = sum(len(imgs) for imgs in results.values())
    print(f"{'='*60}")
    print(f"  âœ… æå–å®Œæˆ! å…± {len(results)} ä»½PDF, {total_images} å¼ å›¾ç‰‡")
    print(f"  ğŸ“ ä¿å­˜è‡³: {output_dir}")
    print(f"{'='*60}\n")

    return results


def main():
    parser = argparse.ArgumentParser(description="ä»ç ”æŠ¥PDFä¸­æå–å›¾ç‰‡")
    parser.add_argument("ticker", type=str, help="æ ‡çš„ä»£ç ï¼Œå¦‚ GOOGL")
    parser.add_argument(
        "--min-size", type=int, default=100,
        help="æœ€å°å›¾ç‰‡å°ºå¯¸ï¼ˆåƒç´ ï¼‰ï¼Œè¿‡æ»¤å°å›¾æ ‡ (é»˜è®¤: 100)"
    )
    args = parser.parse_args()

    extract_images(args.ticker.upper(), args.min_size)


if __name__ == "__main__":
    main()
