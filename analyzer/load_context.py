"""
ç ”æŠ¥åˆ†æç³»ç»Ÿ - ä¸Šä¸‹æ–‡åŠ è½½è„šæœ¬

ç”¨æ³•: uv run python load_context.py TSLA

åŠŸèƒ½: åŠ è½½æ ‡çš„çš„å†å²åˆ†æä¸Šä¸‹æ–‡ï¼Œä¾›Antigravityé˜…è¯»åè¿›è¡Œäº¤å‰å¯¹æ¯”åˆ†æã€‚
è¾“å‡º: è¯¥æ ‡çš„å·²æœ‰ç ”æŠ¥åˆ—è¡¨ã€å…±è¯†æ•°æ®ã€æœºæ„é è°±åº¦ç­‰ä¿¡æ¯ã€‚
"""

import sys
import os
import json

# Windowsç¯å¢ƒä¸‹å¼ºåˆ¶ä½¿ç”¨UTF-8ç¼–ç è¾“å‡º
if sys.platform == "win32":
    os.environ["PYTHONIOENCODING"] = "utf-8"
    sys.stdout.reconfigure(encoding="utf-8")
    sys.stderr.reconfigure(encoding="utf-8")

# å°†analyzerç›®å½•åŠ å…¥è·¯å¾„
sys.path.insert(0, str(__import__("pathlib").Path(__file__).parent))

from lib.data_manager import load_ticker_data, load_scorecard, load_catalysts, get_ticker_info
from lib.backtest_engine import get_unverified_predictions


def load_context(ticker: str) -> None:
    """åŠ è½½å¹¶æ‰“å°æ ‡çš„çš„å®Œæ•´ä¸Šä¸‹æ–‡"""

    print(f"\n{'='*60}")
    print(f"  ğŸ“– {ticker} å†å²ä¸Šä¸‹æ–‡åŠ è½½")
    print(f"{'='*60}\n")

    # 1. æ ‡çš„åŸºæœ¬ä¿¡æ¯
    info = get_ticker_info(ticker)
    if info:
        print(f"ğŸ“Œ æ ‡çš„: {info['symbol']} - {info['name_cn']} ({info['name_en']})")
        print(f"   è¡Œä¸š: {info['sector']}")
        print(f"   é»˜è®¤åˆ†æç»´åº¦: {', '.join(info['default_dimensions'])}")
    else:
        print(f"âš ï¸ æ ‡çš„ {ticker} ä¸åœ¨å…³æ³¨åˆ—è¡¨ä¸­")
        return

    # 2. åŠ è½½æ ‡çš„æ•°æ®
    try:
        ticker_data = load_ticker_data(ticker)
    except FileNotFoundError:
        print(f"âš ï¸ æ ‡çš„æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: data/{ticker}.json")
        return

    # 3. å½“å‰å…±è¯†
    c = ticker_data.current_consensus
    print(f"\nğŸ“Š å½“å‰å…±è¯†:")
    if c.total_reports > 0:
        print(f"   è¯„çº§: {c.rating}")
        print(f"   ç›®æ ‡ä»·: ${c.min_target_price} - ${c.max_target_price} (å‡å€¼: ${c.avg_target_price})")
        print(f"   æƒ…æ„Ÿå‡å€¼: {c.sentiment_avg:+.2f}" if c.sentiment_avg else "   æƒ…æ„Ÿå‡å€¼: -")
        print(f"   ç ”æŠ¥æ€»æ•°: {c.total_reports}")
    else:
        print("   æš‚æ— å·²åˆ†æçš„ç ”æŠ¥")

    # 4. å·²æœ‰ç ”æŠ¥åˆ—è¡¨
    if ticker_data.reports:
        print(f"\nğŸ“„ å·²åˆ†æç ”æŠ¥ ({len(ticker_data.reports)}ç¯‡):")
        print(f"   {'æ—¥æœŸ':<12} {'æœºæ„':<10} {'è¯„çº§':<6} {'ç›®æ ‡ä»·':<10} {'æƒ…æ„Ÿ':<8}")
        print(f"   {'-'*46}")
        for r in sorted(ticker_data.reports, key=lambda x: x.date, reverse=True):
            print(f"   {r.date:<12} {r.institution:<10} {r.rating:<6} ${r.target_price:<9.0f} {r.sentiment_score:+.2f}")

        # 5. å„ç ”æŠ¥æ ¸å¿ƒè§‚ç‚¹æ‘˜è¦
        print(f"\nğŸ¯ å„ç ”æŠ¥æ ¸å¿ƒè§‚ç‚¹:")
        for r in sorted(ticker_data.reports, key=lambda x: x.date, reverse=True):
            print(f"\n   [{r.date}] {r.institution} ({r.rating}, ${r.target_price}):")
            for view in r.views:
                stance_map = {"bullish": "ğŸŸ¢", "neutral": "ğŸŸ¡", "bearish": "ğŸ”´"}
                emoji = stance_map.get(view.stance, "âšª")
                print(f"     {emoji} {view.topic}: {view.summary}")

    # 6. äº¤å‰å¯¹æ¯”ï¼šåˆ†æ­§åˆ†æ
    divergences = ticker_data.cross_comparison.major_divergences
    if divergences:
        print(f"\nâš¡ å½“å‰åˆ†æ­§ç‚¹ ({len(divergences)}ä¸ª):")
        for d in divergences:
            emoji = "ğŸ”´" if d.severity == "major" else "ğŸŸ¡" if d.severity == "moderate" else "ğŸŸ¢"
            print(f"   {emoji} [{d.severity}] {d.topic}")
            print(f"      çœ‹å¤š: {', '.join(d.bulls)}")
            print(f"      çœ‹ç©º: {', '.join(d.bears)}")

    # 7. å…±è¯†çŸ©é˜µ
    matrix = ticker_data.cross_comparison.consensus_matrix
    if matrix:
        print(f"\nğŸ”¥ å…±è¯†çŸ©é˜µ:")
        print(f"   {'ç»´åº¦':<12} {'ğŸŸ¢çœ‹å¤š':<8} {'ğŸŸ¡ä¸­æ€§':<8} {'ğŸ”´çœ‹ç©º':<8}")
        print(f"   {'-'*36}")
        for topic, cm in matrix.items():
            print(f"   {topic:<12} {cm.bullish:<8} {cm.neutral:<8} {cm.bearish:<8}")

    # 8. æœºæ„é è°±åº¦
    scorecard = load_scorecard()
    if scorecard.institutions:
        # ç­›é€‰ä¸è¯¥æ ‡çš„ç›¸å…³çš„æœºæ„
        relevant_insts = []
        for inst in scorecard.institutions:
            if ticker in inst.by_ticker or inst.verified_predictions > 0:
                relevant_insts.append(inst)

        if relevant_insts:
            print(f"\nğŸ“‹ ç›¸å…³æœºæ„é è°±åº¦:")
            print(f"   {'æœºæ„':<10} {'å‡†ç¡®ç‡':<10} {'ç­‰çº§':<6} {'å·²éªŒè¯':<8}")
            print(f"   {'-'*34}")
            for inst in relevant_insts:
                print(
                    f"   {inst.name:<10} {inst.accuracy_rate:.0%}{'':>5} "
                    f"{inst.reliability_tier:<6} {inst.verified_predictions}/{inst.total_predictions}"
                )

    # 9. å¾…éªŒè¯çš„é¢„æµ‹
    unverified = get_unverified_predictions(ticker)
    if unverified:
        print(f"\nâ³ å¾…éªŒè¯çš„é¢„æµ‹ ({len(unverified)}ä¸ª):")
        for uv in unverified:
            print(f"   [{uv['date']}] {uv['institution']}: {uv['metric']} = {uv['predicted_value']} (æˆªæ­¢{uv['deadline']})")

    # 10. ç›¸å…³å‚¬åŒ–å‰‚
    calendar = load_catalysts()
    relevant_cats = [c for c in calendar.catalysts if c.ticker == ticker and not c.verified]
    if relevant_cats:
        print(f"\nğŸ“… å³å°†åˆ°æ¥çš„å‚¬åŒ–å‰‚:")
        for cat in relevant_cats:
            imp_map = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}
            emoji = imp_map.get(cat.importance, "âšª")
            print(f"   {emoji} {cat.date} - {cat.event}")

    print(f"\n{'='*60}")
    print(f"  âœ… ä¸Šä¸‹æ–‡åŠ è½½å®Œæˆ")
    print(f"{'='*60}\n")


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•: uv run python load_context.py <TICKER>")
        print("ç¤ºä¾‹: uv run python load_context.py TSLA")
        sys.exit(1)

    ticker = sys.argv[1].upper()
    load_context(ticker)
