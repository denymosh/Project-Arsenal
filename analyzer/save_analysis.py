"""
ç ”æŠ¥åˆ†æç³»ç»Ÿ - åˆ†æç»“æœä¿å­˜è„šæœ¬

ç”¨æ³•: uv run python save_analysis.py TSLA --input=tmp_analysis.json

åŠŸèƒ½:
  1. è¯»å–Antigravityè¾“å‡ºçš„åˆ†æJSON
  2. ç”Ÿæˆåˆ†æMDæŠ¥å‘Š
  3. æ›´æ–°æ ‡çš„JSONæ•°æ®ï¼ˆè¿½åŠ ç ”æŠ¥ + é‡ç®—å…±è¯† + æ›´æ–°äº¤å‰å¯¹æ¯”ï¼‰
  4. æ›´æ–°å‚¬åŒ–å‰‚æ—¥å†
  5. æ›´æ–°è®°åˆ†æ¿ï¼ˆæ–°æœºæ„æ³¨å†Œï¼‰
  6. é‡æ–°ç”Ÿæˆæ ‡çš„æ±‡æ€»MD
"""

import sys
import os
import json
import argparse
from pathlib import Path

# Windowsç¯å¢ƒä¸‹å¼ºåˆ¶ä½¿ç”¨UTF-8ç¼–ç è¾“å‡º
if sys.platform == "win32":
    os.environ["PYTHONIOENCODING"] = "utf-8"
    sys.stdout.reconfigure(encoding="utf-8")
    sys.stderr.reconfigure(encoding="utf-8")

# å°†analyzerç›®å½•åŠ å…¥è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from lib.models import AnalysisInput
from lib.data_manager import (
    add_report_to_ticker,
    ensure_institution_in_scorecard,
    add_catalysts_from_report,
    PROJECT_ROOT
)
from lib.consensus import update_consensus, update_consensus_matrix
from lib.cross_validator import find_divergences
from lib.report_generator import generate_analysis_md, generate_summary_md


def save_analysis(ticker: str, input_path: str) -> None:
    """æ‰§è¡Œå®Œæ•´çš„åˆ†æä¿å­˜æµç¨‹"""

    print(f"\n{'='*60}")
    print(f"  ğŸ’¾ ä¿å­˜ {ticker} ç ”æŠ¥åˆ†æç»“æœ")
    print(f"{'='*60}\n")

    # 1. è¯»å–åˆ†æJSON
    filepath = Path(input_path)
    if not filepath.is_absolute():
        filepath = PROJECT_ROOT / filepath

    if not filepath.exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
        sys.exit(1)

    with open(filepath, "r", encoding="utf-8") as f:
        raw_data = json.load(f)

    # 2. éªŒè¯æ•°æ®æ ¼å¼
    try:
        analysis = AnalysisInput.model_validate(raw_data)
    except Exception as e:
        print(f"âŒ æ•°æ®æ ¼å¼éªŒè¯å¤±è´¥: {e}")
        sys.exit(1)

    print(f"  ğŸ“„ ç ”æŠ¥: {analysis.report.institution} ({analysis.report.date})")
    print(f"     è¯„çº§: {analysis.report.rating} | ç›®æ ‡ä»·: ${analysis.report.target_price}")

    # 3. æ·»åŠ ç ”æŠ¥åˆ°æ ‡çš„æ•°æ®
    print(f"\n  [1/6] æ·»åŠ ç ”æŠ¥è®°å½•...")
    stored_report = add_report_to_ticker(ticker, analysis)

    # 4. ç¡®ä¿æœºæ„åœ¨è®°åˆ†æ¿ä¸­
    print(f"  [2/6] æ›´æ–°è®°åˆ†æ¿...")
    ensure_institution_in_scorecard(
        analysis.report.institution,
        analysis.report.institution_en
    )

    # 5. é‡æ–°è®¡ç®—å…±è¯†
    print(f"  [3/6] é‡æ–°è®¡ç®—å…±è¯†...")
    update_consensus(ticker)
    update_consensus_matrix(ticker)

    # 6. äº¤å‰éªŒè¯
    print(f"  [4/6] æ‰§è¡Œäº¤å‰éªŒè¯...")
    find_divergences(ticker)

    # 7. æ›´æ–°å‚¬åŒ–å‰‚æ—¥å†
    if analysis.report.catalysts:
        print(f"  [5/6] æ›´æ–°å‚¬åŒ–å‰‚æ—¥å†...")
        catalysts_data = [cat.model_dump() for cat in analysis.report.catalysts]
        add_catalysts_from_report(
            ticker, stored_report.id,
            analysis.report.institution,
            catalysts_data
        )
    else:
        print(f"  [5/6] æ— æ–°å‚¬åŒ–å‰‚äº‹ä»¶")

    # 8. ç”Ÿæˆåˆ†æMDæŠ¥å‘Š
    print(f"  [6/6] ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶...")
    generate_analysis_md(ticker, stored_report)
    generate_summary_md(ticker)

    print(f"\n{'='*60}")
    print(f"  âœ… ä¿å­˜å®Œæˆ!")
    print(f"     åˆ†ææ–‡ä»¶: {stored_report.analysis_file}")
    print(f"     æ•°æ®æ–‡ä»¶: data/{ticker}.json")
    print(f"{'='*60}\n")


def main():
    parser = argparse.ArgumentParser(description="ä¿å­˜ç ”æŠ¥åˆ†æç»“æœ")
    parser.add_argument("ticker", type=str, help="æ ‡çš„ä»£ç ï¼Œå¦‚ TSLA")
    parser.add_argument("--input", "-i", type=str, required=True, help="åˆ†æJSONæ–‡ä»¶è·¯å¾„")
    args = parser.parse_args()

    save_analysis(args.ticker.upper(), args.input)


if __name__ == "__main__":
    main()
