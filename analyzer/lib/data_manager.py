"""
ç ”æŠ¥åˆ†æç³»ç»Ÿ - JSONæ•°æ®ç®¡ç†å™¨

è´Ÿè´£æ‰€æœ‰JSONæ–‡ä»¶çš„è¯»å–ã€å†™å…¥ã€æ›´æ–°å’Œåˆå¹¶æ“ä½œã€‚
"""

import json
import os
from pathlib import Path
from typing import Optional
from datetime import date

from .models import (
    TickerData, StoredReport, Scorecard, InstitutionScore,
    CatalystCalendar, CatalystEvent, AnalysisInput,
    CurrentConsensus, SentimentRecord, PredictionToVerify
)


# é¡¹ç›®æ ¹ç›®å½•ï¼ˆanalyzerçš„ä¸Šä¸€çº§ï¼‰
PROJECT_ROOT = Path(__file__).parent.parent.parent
DATA_DIR = PROJECT_ROOT / "data"
REPORTS_DIR = PROJECT_ROOT / "reports"


def get_data_dir() -> Path:
    """è·å–dataç›®å½•è·¯å¾„"""
    return DATA_DIR


def get_reports_dir() -> Path:
    """è·å–reportsç›®å½•è·¯å¾„"""
    return REPORTS_DIR


# ============================================================
# é€šç”¨JSONè¯»å†™
# ============================================================
def read_json(filepath: Path) -> dict:
    """è¯»å–JSONæ–‡ä»¶ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨è¿”å›ç©ºå­—å…¸"""
    if not filepath.exists():
        return {}
    with open(filepath, "r", encoding="utf-8") as f:
        return json.load(f)


def write_json(filepath: Path, data: dict) -> None:
    """å†™å…¥JSONæ–‡ä»¶ï¼Œè‡ªåŠ¨åˆ›å»ºçˆ¶ç›®å½•"""
    filepath.parent.mkdir(parents=True, exist_ok=True)
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"  âœ… å·²å†™å…¥: {filepath.relative_to(PROJECT_ROOT)}")


# ============================================================
# æ ‡çš„æ•°æ®æ“ä½œ
# ============================================================
def load_ticker_data(ticker: str) -> TickerData:
    """åŠ è½½æ ‡çš„æ•°æ®æ–‡ä»¶"""
    filepath = DATA_DIR / f"{ticker}.json"
    if not filepath.exists():
        raise FileNotFoundError(f"æ ‡çš„æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
    raw = read_json(filepath)
    return TickerData.model_validate(raw)


def ensure_ticker_registered(ticker: str) -> None:
    """ç¡®ä¿æ ‡çš„å·²æ³¨å†Œåˆ° tickers.json ä¸”å­˜åœ¨ data/{ticker}.jsonã€‚"""
    ticker = ticker.upper()

    # 1) æ³¨å†Œåˆ° tickers.json
    tickers_path = DATA_DIR / "tickers.json"
    raw = read_json(tickers_path)
    items = raw.get("tickers", [])
    exists = any((x.get("symbol") or "").upper() == ticker for x in items)
    if not exists:
        items.append({
            "symbol": ticker,
            "name_en": ticker,
            "name_cn": ticker,
            "sector": "å¾…è¡¥å……",
            "default_dimensions": ["æ ¸å¿ƒä¸šåŠ¡", "å¢é•¿", "åˆ©æ¶¦ç‡", "ç°é‡‘æµ", "ç«äº‰æ ¼å±€", "ä¼°å€¼"],
        })
        raw["tickers"] = sorted(items, key=lambda x: (x.get("symbol") or ""))
        raw["last_updated"] = date.today().isoformat()
        write_json(tickers_path, raw)
        print(f"  ğŸ†• å·²è‡ªåŠ¨æ³¨å†Œæ–°æ ‡çš„: {ticker}")

    # 2) åˆ›å»º data/{ticker}.json ç©ºå£³
    ticker_path = DATA_DIR / f"{ticker}.json"
    if not ticker_path.exists():
        stub = TickerData(
            ticker=ticker,
            name_en=ticker,
            name_cn=ticker,
        )
        write_json(ticker_path, stub.model_dump())
        print(f"  ğŸ†• å·²åˆå§‹åŒ–æ•°æ®æ–‡ä»¶: data/{ticker}.json")


def save_ticker_data(ticker_data: TickerData) -> None:
    """ä¿å­˜æ ‡çš„æ•°æ®æ–‡ä»¶"""
    filepath = DATA_DIR / f"{ticker_data.ticker}.json"
    write_json(filepath, ticker_data.model_dump())


def generate_report_id(report_date: str, institution_en: str) -> str:
    """
    ç”Ÿæˆç ”æŠ¥å”¯ä¸€ID
    æ ¼å¼: YYYYMMDD_institutionï¼ˆå°å†™ä¸‹åˆ’çº¿è¿æ¥ï¼‰
    ä¾‹å¦‚: 20260217_goldman_sachs
    """
    date_part = report_date.replace("-", "")
    inst_part = institution_en.lower().replace(" ", "_").replace(".", "")
    return f"{date_part}_{inst_part}"


def add_report_to_ticker(ticker: str, analysis: AnalysisInput) -> StoredReport:
    """
    å°†ä¸€ç¯‡æ–°çš„ç ”æŠ¥åˆ†æç»“æœæ·»åŠ åˆ°æ ‡çš„æ•°æ®ä¸­

    å‚æ•°:
        ticker: æ ‡çš„ä»£ç 
        analysis: Antigravityè¾“å‡ºçš„åˆ†æç»“æœ

    è¿”å›:
        StoredReport: å­˜å‚¨åçš„ç ”æŠ¥è®°å½•
    """
    # ç¡®ä¿æ–°æ ‡çš„å¯è‡ªåŠ¨æ³¨å†Œå¹¶åˆå§‹åŒ–
    ensure_ticker_registered(ticker)

    # åŠ è½½ç°æœ‰æ•°æ®
    ticker_data = load_ticker_data(ticker)
    report = analysis.report

    # ç”ŸæˆID
    report_id = generate_report_id(report.date, report.institution_en or report.institution)

    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆé˜²æ­¢é‡å¤æ·»åŠ ï¼‰
    existing_ids = [r.id for r in ticker_data.reports]
    if report_id in existing_ids:
        print(f"  âš ï¸ ç ”æŠ¥ {report_id} å·²å­˜åœ¨ï¼Œå°†è¦†ç›–æ›´æ–°")
        ticker_data.reports = [r for r in ticker_data.reports if r.id != report_id]

    # æ„å»ºå­˜å‚¨è®°å½•
    analysis_filename = f"{report.date}_{report.institution}_{report.rating}_åˆ†æ.md"
    analysis_path = f"reports/{ticker}/analysis/{analysis_filename}"

    stored = StoredReport(
        id=report_id,
        analysis_file=analysis_path,
        **report.model_dump()
    )

    # è¿½åŠ åˆ°æŠ¥å‘Šåˆ—è¡¨
    ticker_data.reports.append(stored)

    # æ·»åŠ æƒ…æ„Ÿå†å²è®°å½•
    ticker_data.sentiment_history.append(SentimentRecord(
        date=report.date,
        institution=report.institution,
        score=report.sentiment_score
    ))

    # æ›´æ–°ç»´åº¦åˆ—è¡¨ï¼ˆåˆå¹¶æ–°è§‚ç‚¹çš„ç»´åº¦ï¼‰
    for view in report.views:
        if view.topic not in ticker_data.view_dimensions:
            ticker_data.view_dimensions.append(view.topic)

    # ä¿å­˜
    save_ticker_data(ticker_data)

    return stored


# ============================================================
# è®°åˆ†æ¿æ“ä½œ
# ============================================================
def load_scorecard() -> Scorecard:
    """åŠ è½½è®°åˆ†æ¿æ•°æ®"""
    filepath = DATA_DIR / "scorecard.json"
    raw = read_json(filepath)
    return Scorecard.model_validate(raw)


def save_scorecard(scorecard: Scorecard) -> None:
    """ä¿å­˜è®°åˆ†æ¿æ•°æ®"""
    filepath = DATA_DIR / "scorecard.json"
    write_json(filepath, scorecard.model_dump())


def ensure_institution_in_scorecard(
    institution: str, institution_en: str = ""
) -> None:
    """ç¡®ä¿æœºæ„åœ¨è®°åˆ†æ¿ä¸­æœ‰è®°å½•ï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»º"""
    scorecard = load_scorecard()
    existing_names = [inst.name for inst in scorecard.institutions]
    if institution not in existing_names:
        scorecard.institutions.append(InstitutionScore(
            name=institution,
            name_en=institution_en
        ))
        scorecard.last_updated = date.today().isoformat()
        save_scorecard(scorecard)
        print(f"  ğŸ“‹ å·²åœ¨è®°åˆ†æ¿ä¸­æ·»åŠ æ–°æœºæ„: {institution}")


# ============================================================
# å‚¬åŒ–å‰‚æ—¥å†æ“ä½œ
# ============================================================
def load_catalysts() -> CatalystCalendar:
    """åŠ è½½å‚¬åŒ–å‰‚æ—¥å†"""
    filepath = DATA_DIR / "catalysts.json"
    raw = read_json(filepath)
    return CatalystCalendar.model_validate(raw)


def save_catalysts(calendar: CatalystCalendar) -> None:
    """ä¿å­˜å‚¬åŒ–å‰‚æ—¥å†"""
    filepath = DATA_DIR / "catalysts.json"
    write_json(filepath, calendar.model_dump())


def add_catalysts_from_report(
    ticker: str, report_id: str, institution: str,
    catalysts: list[dict]
) -> None:
    """
    ä»ç ”æŠ¥åˆ†æç»“æœä¸­æå–å‚¬åŒ–å‰‚äº‹ä»¶å¹¶æ·»åŠ åˆ°æ—¥å†

    å¦‚æœç›¸åŒäº‹ä»¶å·²å­˜åœ¨ï¼Œåˆ™åˆå¹¶ç ”æŠ¥å¼•ç”¨ï¼›å¦‚æœæ˜¯æ–°äº‹ä»¶åˆ™æ–°å¢ã€‚
    """
    calendar = load_catalysts()

    for cat in catalysts:
        event_name = cat.get("event", "")
        event_date = cat.get("expected_date", "")

        # ç”Ÿæˆå‚¬åŒ–å‰‚ID
        cat_id = f"{ticker.lower()}_{event_name.replace(' ', '_').lower()[:30]}"

        # æŸ¥æ‰¾æ˜¯å¦å·²å­˜åœ¨ç›¸åŒäº‹ä»¶
        existing = None
        for existing_cat in calendar.catalysts:
            if existing_cat.ticker == ticker and existing_cat.event == event_name:
                existing = existing_cat
                break

        if existing:
            # å·²å­˜åœ¨ï¼šè¿½åŠ ç ”æŠ¥å¼•ç”¨
            if report_id not in existing.related_reports:
                existing.related_reports.append(report_id)
                # æ·»åŠ è¯¥ç ”æŠ¥çš„é¢„æµ‹åˆ°å¾…éªŒè¯åˆ—è¡¨
                for view in cat.get("related_views", []):
                    existing.predictions_to_verify.append(PredictionToVerify(
                        report_id=report_id,
                        institution=institution,
                        metric=event_name,
                        value=f"è§{institution}ç ”æŠ¥åˆ†æ"
                    ))
        else:
            # æ–°äº‹ä»¶ï¼šåˆ›å»ºå‚¬åŒ–å‰‚è®°å½•
            new_catalyst = CatalystEvent(
                id=cat_id,
                date=event_date,
                ticker=ticker,
                event=event_name,
                importance=cat.get("importance", "medium"),
                related_reports=[report_id],
                predictions_to_verify=[]
            )
            calendar.catalysts.append(new_catalyst)

    # æŒ‰æ—¥æœŸæ’åº
    calendar.catalysts.sort(key=lambda c: c.date)
    calendar.last_updated = date.today().isoformat()
    save_catalysts(calendar)


# ============================================================
# æ ‡çš„åˆ—è¡¨æ“ä½œ
# ============================================================
def get_all_tickers() -> list[str]:
    """è·å–æ‰€æœ‰å…³æ³¨æ ‡çš„çš„ä»£ç åˆ—è¡¨"""
    filepath = DATA_DIR / "tickers.json"
    raw = read_json(filepath)
    return [t["symbol"] for t in raw.get("tickers", [])]


def get_ticker_info(ticker: str) -> Optional[dict]:
    """è·å–æ ‡çš„çš„åŸºæœ¬ä¿¡æ¯"""
    filepath = DATA_DIR / "tickers.json"
    raw = read_json(filepath)
    for t in raw.get("tickers", []):
        if t["symbol"] == ticker:
            return t
    return None
